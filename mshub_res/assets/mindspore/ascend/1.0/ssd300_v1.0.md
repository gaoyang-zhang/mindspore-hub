# SSD

---

model-name: ssd300

backbone-name: mobilenetV2

module-type: cv-object_detection

fine-tunable: True

input-shape: [300, 300, 3]

model-version: 1

author: MindSpore team

update-time: 2020-09-10

repo-link: <https://gitee.com/mindspore/mindspore/tree/master/model_zoo/official/cv/ssd>

user-id: MindSpore

used-for: inference

train-backend: ascend

infer-backend: ascend

mindspore-version: 1.0

asset:

  -
    file-format: air  
    asset-link: <https://download.mindspore.cn/model_zoo/official/lite/ssd_mobilenetv2_lite/ssd.geir>  
    asset-sha256: a385d49b3471582fbfec4a762afec771fe36a9dec706a4614256126641c5e7cc  

  -
    file-format: mslite  
    asset-link: <https://download.mindspore.cn/model_zoo/official/lite/ssd_mobilenetv2_lite/ssd.ms>  
    asset-sha256: e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855  

license: Apache2.0

summary: ssd with the shape 300 * 300 for object detection

---

## Introduction

This MindSpore Hub model uses the implementation of SSD from the MindSpore model zoo on Gitee at model_zoo/official/cv/ssd.

SSD is a one-stage object detection network. More details please refer to the [MindSpore model zoo on Gitee](https://gitee.com/mindspore/mindspore/blob/master/model_zoo/official/cv/ssd/README.md).

All parameters in the module are trainable.

## Lite Inference  Usage

```cpp
bool BitmapToLiteMat(JNIEnv *env, const jobject &srcBitmap, LiteMat *lite_mat) {
  bool ret = false;
  AndroidBitmapInfo info;
  void *pixels = nullptr;
  LiteMat &lite_mat_bgr = *lite_mat;
  AndroidBitmap_getInfo(env, srcBitmap, &info);
  if (info.format != ANDROID_BITMAP_FORMAT_RGBA_8888) {
    MS_PRINT("Image Err, Request RGBA");
    return false;
  }
  AndroidBitmap_lockPixels(env, srcBitmap, &pixels);
  if (info.stride == info.width * 4) {
    ret = InitFromPixel(reinterpret_cast<const unsigned char *>(pixels),
                        LPixelType::RGBA2RGB, LDataType::UINT8,
                        info.width, info.height, lite_mat_bgr);
    if (!ret) {
      MS_PRINT("Init From RGBA error");
    }
  } else {
    unsigned char *pixels_ptr = new unsigned char[info.width * info.height * 4];
    unsigned char *ptr = pixels_ptr;
    unsigned char *data = reinterpret_cast<unsigned char *>(pixels);
    for (int i = 0; i < info.height; i++) {
      memcpy(ptr, data, info.width * 4);
      ptr += info.width * 4;
      data += info.stride;
    }
    ret = InitFromPixel(reinterpret_cast<const unsigned char *>(pixels_ptr),
                        LPixelType::RGBA2RGB, LDataType::UINT8,
                        info.width, info.height, lite_mat_bgr);
    if (!ret) {
      MS_PRINT("Init From RGBA error");
    }
    delete[] (pixels_ptr);
  }
  AndroidBitmap_unlockPixels(env, srcBitmap);
  return ret;
}
```

Pre-Process the imagedata and  convert the input image into the Tensor format of the MindSpore model.

   ```cpp
   // Convert the Bitmap image passed in from the JAVA layer to Mat for OpenCV processing
       LiteMat lite_mat_bgr,lite_norm_mat_cut;

       if (!BitmapToLiteMat(env, srcBitmap, lite_mat_bgr)){
           MS_PRINT("BitmapToLiteMat error");
           return NULL;
       }
       int srcImageWidth = lite_mat_bgr.width_;
       int srcImageHeight = lite_mat_bgr.height_;
       if(!PreProcessImageData(lite_mat_bgr, lite_norm_mat_cut)){
           MS_PRINT("PreProcessImageData error");
           return NULL;
       }
       ImgDims inputDims;
       inputDims.channel =lite_norm_mat_cut.channel_;
       inputDims.width = lite_norm_mat_cut.width_;
       inputDims.height = lite_norm_mat_cut.height_;

       // Get the mindsore inference environment which created in loadModel().
       void **labelEnv = reinterpret_cast<void **>(netEnv);
       if (labelEnv == nullptr) {
           MS_PRINT("MindSpore error, labelEnv is a nullptr.");
           return NULL;
       }
       MSNetWork *labelNet = static_cast<MSNetWork *>(*labelEnv);

       auto mSession = labelNet->session;
       if (mSession == nullptr) {
           MS_PRINT("MindSpore error, Session is a nullptr.");
           return NULL;
       }
       MS_PRINT("MindSpore get session.");

       auto msInputs = mSession->GetInputs();
       auto inTensor = msInputs.front();

       float *dataHWC = reinterpret_cast<float *>(lite_norm_mat_cut.data_ptr_);
       // copy input Tensor
       memcpy(inTensor->MutableData(), dataHWC,
              inputDims.channel * inputDims.width * inputDims.height * sizeof(float));
       delete[] (dataHWC);
   ```

   The input image shall be NHWC(1:300:300:3).

   ```cpp
    bool PreProcessImageData(const LiteMat &lite_mat_bgr, LiteMat *lite_norm_mat_ptr) {
        bool ret = false;
        LiteMat lite_mat_resize;
        LiteMat &lite_norm_mat_cut = *lite_norm_mat_ptr;
        ret = ResizeBilinear(lite_mat_bgr, lite_mat_resize, 300, 300);
        if (!ret) {
            MS_PRINT("ResizeBilinear error");
            return false;
        }
        LiteMat lite_mat_convert_float;
        ret = ConvertTo(lite_mat_resize, lite_mat_convert_float, 1.0 / 255.0);
        if (!ret) {
            MS_PRINT("ConvertTo error");
            return false;
        }

        float means[3] = {0.485, 0.456, 0.406};
        float vars[3] = {1.0 / 0.229, 1.0 / 0.224, 1.0 / 0.225};
        SubStractMeanNormalize(lite_mat_convert_float, lite_norm_mat_cut, means, vars);
        return true;
    }

   ```

   Perform inference on the input tensor based on the model, obtain the output tensor, and perform post-processing.
   Perform graph execution and on-device inference.

   ```cpp
   // After the model and image tensor data is loaded, run inference.
   auto status = mSession->RunGraph();
   ```

   Obtain the output data.

   ```cpp
    auto names = mSession->GetOutputTensorNames();
       typedef std::unordered_map<std::string,
               std::vector<mindspore::tensor::MSTensor *>> Msout;
    std::unordered_map<std::string,
               mindspore::tensor::MSTensor *> msOutputs;
    for (const auto &name : names) {
           auto temp_dat =mSession->GetOutputByTensorName(name);
           msOutputs.insert(std::pair<std::string, mindspore::tensor::MSTensor *> {name, temp_dat});
       }
   std::string retStr = ProcessRunnetResult(msOutputs, ret);
   ```

   The model output the object category scores (1:1917:81) and the object detection location offset (1:1917:4). The location offset can be calcalation the object location in getDefaultBoxes function .

   ```cpp
   void SSDModelUtil::getDefaultBoxes() {
       float fk[6] = {0.0, 0.0, 0.0, 0.0, 0.0, 0.0};
       std::vector<struct WHBox> all_sizes;
       struct Product mProductData[19 * 19] = {0};

       for (int i = 0; i < 6; i++) {
           fk[i] = config.model_input_height / config.steps[i];
       }
       float scale_rate =
               (config.max_scale - config.min_scale) / (sizeof(config.num_default) / sizeof(int) - 1);
       float scales[7] = {0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0};
       for (int i = 0; i < sizeof(config.num_default) / sizeof(int); i++) {
           scales[i] = config.min_scale + scale_rate * i;
       }

       for (int idex = 0; idex < sizeof(config.feature_size) / sizeof(int); idex++) {
           float sk1 = scales[idex];
           float sk2 = scales[idex + 1];
           float sk3 = sqrt(sk1 * sk2);
           struct WHBox tempWHBox;

           all_sizes.clear();

           if (idex == 0) {
               float w = sk1 * sqrt(2);
               float h = sk1 / sqrt(2);

               tempWHBox.boxw = 0.1;
               tempWHBox.boxh = 0.1;
               all_sizes.push_back(tempWHBox);

               tempWHBox.boxw = w;
               tempWHBox.boxh = h;
               all_sizes.push_back(tempWHBox);

               tempWHBox.boxw = h;
               tempWHBox.boxh = w;
               all_sizes.push_back(tempWHBox);

           } else {
               tempWHBox.boxw = sk1;
               tempWHBox.boxh = sk1;
               all_sizes.push_back(tempWHBox);

               for (int j = 0; j < sizeof(config.aspect_ratios[idex]) / sizeof(int); j++) {
                   float w = sk1 * sqrt(config.aspect_ratios[idex][j]);
                   float h = sk1 / sqrt(config.aspect_ratios[idex][j]);
                   tempWHBox.boxw = w;
                   tempWHBox.boxh = h;
                   all_sizes.push_back(tempWHBox);
                   tempWHBox.boxw = h;
                   tempWHBox.boxh = w;
                   all_sizes.push_back(tempWHBox);
               }

               tempWHBox.boxw = sk3;
               tempWHBox.boxh = sk3;
               all_sizes.push_back(tempWHBox);
           }

           for (int i = 0; i < config.feature_size[idex]; i++) {
               for (int j = 0; j < config.feature_size[idex]; j++) {
                   mProductData[i * config.feature_size[idex] + j].x = i;
                   mProductData[i * config.feature_size[idex] + j].y = j;
               }
           }

           int productLen = config.feature_size[idex] * config.feature_size[idex];

           for (int i = 0; i < productLen; i++) {
               for (int j = 0; j < all_sizes.size(); j++) {
                   struct NormalBox tempBox;
                   float cx = (mProductData[i].y + 0.5) / fk[idex];
                   float cy = (mProductData[i].x + 0.5) / fk[idex];
                   tempBox.y = cy;
                   tempBox.x = cx;
                   tempBox.h = all_sizes[j].boxh;
                   tempBox.w = all_sizes[j].boxw;
                   mDefaultBoxes.push_back(tempBox);
               }
           }
       }
   }
   ```

- The higher scores and location of category can be calcluted by the nonMaximumSuppression function.

    ```cpp
    void SSDModelUtil::nonMaximumSuppression(const YXBoxes *const decoded_boxes,
                                             const float *const scores,
                                             const std::vector<int> &in_indexes,
                                             std::vector<int> &out_indexes, const float nmsThreshold,
                                             const int count, const int max_results) {
        int nR = 0; //number of results
        std::vector<bool> del(count, false);
        for (size_t i = 0; i < in_indexes.size(); i++) {
            if (!del[in_indexes[i]]) {
                out_indexes.push_back(in_indexes[i]);
                if (++nR == max_results) {
                    break;
                }
                for (size_t j = i + 1; j < in_indexes.size(); j++) {
                    const auto boxi = decoded_boxes[in_indexes[i]], boxj = decoded_boxes[in_indexes[j]];
                    float a[4] = {boxi.xmin, boxi.ymin, boxi.xmax, boxi.ymax};
                    float b[4] = {boxj.xmin, boxj.ymin, boxj.xmax, boxj.ymax};
                    if (IOU(a, b) > nmsThreshold) {
                        del[in_indexes[j]] = true;
                    }
                }
            }
        }
    }
    ```

- For the targets whose probability is greater than the threshold value, the output rectangle box needs to be restored to the original size after the rectangular box is filtered by NMS algorithm.

    ```cpp
    std::string SSDModelUtil::getDecodeResult(float *branchScores, float *branchBoxData) {
        std::string result = "";
        NormalBox tmpBox[1917] = {0};
        float mScores[1917][81] = {0};

        float outBuff[1917][7] = {0};

        float scoreWithOneClass[1917] = {0};
        int outBoxNum = 0;
        YXBoxes decodedBoxes[1917] = {0};

        // Copy branch outputs box data to tmpBox.
        for (int i = 0; i < 1917; ++i) {
            tmpBox[i].y = branchBoxData[i * 4 + 0];
            tmpBox[i].x = branchBoxData[i * 4 + 1];
            tmpBox[i].h = branchBoxData[i * 4 + 2];
            tmpBox[i].w = branchBoxData[i * 4 + 3];
        }

        // Copy branch outputs score to mScores.
        for (int i = 0; i < 1917; ++i) {
            for (int j = 0; j < 81; ++j) {
                mScores[i][j] = branchScores[i * 81 + j];
            }
        }

        // NMS processing.
        ssd_boxes_decode(tmpBox, decodedBoxes);
        // const float nms_threshold = 0.6;
        const float nms_threshold = 0.3;
        for (int i = 1; i < 81; i++) {
            std::vector<int> in_indexes;
            for (int j = 0; j < 1917; j++) {
                scoreWithOneClass[j] = mScores[j][i];
                // if (mScores[j][i] > 0.1) {
                if (mScores[j][i] > g_thres_map[i]) {
                    in_indexes.push_back(j);
                }
            }
            if (in_indexes.size() == 0) {
                continue;
            }

            sort(in_indexes.begin(), in_indexes.end(),
                 [&](int a, int b) { return scoreWithOneClass[a] > scoreWithOneClass[b]; });
            std::vector<int> out_indexes;

            nonMaximumSuppression(decodedBoxes, scoreWithOneClass, in_indexes, out_indexes,
                                  nms_threshold);
            for (int k = 0; k < out_indexes.size(); k++) {
                outBuff[outBoxNum][0] = out_indexes[k]; //image id
                outBuff[outBoxNum][1] = i; //labelid
                outBuff[outBoxNum][2] = scoreWithOneClass[out_indexes[k]]; //scores
                outBuff[outBoxNum][3] =
                        decodedBoxes[out_indexes[k]].xmin * inputImageWidth / 300;
                outBuff[outBoxNum][4] =
                        decodedBoxes[out_indexes[k]].ymin * inputImageHeight / 300;
                outBuff[outBoxNum][5] =
                        decodedBoxes[out_indexes[k]].xmax * inputImageWidth / 300;
                outBuff[outBoxNum][6] =
                        decodedBoxes[out_indexes[k]].ymax * inputImageHeight / 300;
                outBoxNum++;
            }
        }
        MS_PRINT("outBoxNum %d", outBoxNum);

        for (int i = 0; i < outBoxNum; ++i) {
            std::string tmpid_str = std::to_string(outBuff[i][0]);
            result += tmpid_str; // image ID
            result += "_";
            // tmpid_str = std::to_string(outBuff[i][1]);
            MS_PRINT("label_classes i %d, outBuff %d",i, (int) outBuff[i][1]);
            tmpid_str = label_classes[(int) outBuff[i][1]];
            result += tmpid_str; // label id
            result += "_";
            tmpid_str = std::to_string(outBuff[i][2]);
            result += tmpid_str; // scores
            result += "_";
            tmpid_str = std::to_string(outBuff[i][3]);
            result += tmpid_str; // xmin
            result += "_";
            tmpid_str = std::to_string(outBuff[i][4]);
            result += tmpid_str; // ymin
            result += "_";
            tmpid_str = std::to_string(outBuff[i][5]);
            result += tmpid_str; // xmax
            result += "_";
            tmpid_str = std::to_string(outBuff[i][6]);
            result += tmpid_str; // ymax
            result += ";";
        }

        return result;
    }
    std::string SSDModelUtil::getDecodeResult(float *branchScores, float *branchBoxData) {
        std::string result = "";
        NormalBox tmpBox[1917] = {0};
        float mScores[1917][81] = {0};
        float outBuff[1917][7] = {0};
        float scoreWithOneClass[1917] = {0};
        int outBoxNum = 0;
        YXBoxes decodedBoxes[1917] = {0};

        // Copy branch outputs box data to tmpBox.
        for (int i = 0; i < 1917; ++i) {
            tmpBox[i].y = branchBoxData[i * 4 + 0];
            tmpBox[i].x = branchBoxData[i * 4 + 1];
            tmpBox[i].h = branchBoxData[i * 4 + 2];
            tmpBox[i].w = branchBoxData[i * 4 + 3];
        }

        // Copy branch outputs score to mScores.
        for (int i = 0; i < 1917; ++i) {
            for (int j = 0; j < 81; ++j) {
                mScores[i][j] = branchScores[i * 81 + j];
            }
        }

        ssd_boxes_decode(tmpBox, decodedBoxes);
        const float nms_threshold = 0.3;
        for (int i = 1; i < 81; i++) {
            std::vector<int> in_indexes;
            for (int j = 0; j < 1917; j++) {
                scoreWithOneClass[j] = mScores[j][i];
                if (mScores[j][i] > g_thres_map[i]) {
                    in_indexes.push_back(j);
                }
            }
            if (in_indexes.size() == 0) {
                continue;
            }

            sort(in_indexes.begin(), in_indexes.end(),
                [&](int a, int b) { return scoreWithOneClass[a] > scoreWithOneClass[b]; });
            std::vector<int> out_indexes;

            nonMaximumSuppression(decodedBoxes, scoreWithOneClass, in_indexes, out_indexes,
                                   nms_threshold);
            for (int k = 0; k < out_indexes.size(); k++) {
                outBuff[outBoxNum][0] = out_indexes[k]; //image id
                outBuff[outBoxNum][1] = i; //labelid
                outBuff[outBoxNum][2] = scoreWithOneClass[out_indexes[k]]; //scores
                outBuff[outBoxNum][3] =
                         decodedBoxes[out_indexes[k]].xmin * inputImageWidth / 300;
                outBuff[outBoxNum][4] =
                         decodedBoxes[out_indexes[k]].ymin * inputImageHeight / 300;
                outBuff[outBoxNum][5] =
                         decodedBoxes[out_indexes[k]].xmax * inputImageWidth / 300;
                outBuff[outBoxNum][6] =
                         decodedBoxes[out_indexes[k]].ymax * inputImageHeight / 300;
                outBoxNum++;
            }
        }
        MS_PRINT("outBoxNum %d", outBoxNum);

        for (int i = 0; i < outBoxNum; ++i) {
            std::string tmpid_str = std::to_string(outBuff[i][0]);
            result += tmpid_str; // image ID
            result += "_";
            // tmpid_str = std::to_string(outBuff[i][1]);
            MS_PRINT("label_classes i %d, outBuff %d",i, (int) outBuff[i][1]);
            tmpid_str = label_classes[(int) outBuff[i][1]];
            result += tmpid_str; // label id
            result += "_";
            tmpid_str = std::to_string(outBuff[i][2]);
            result += tmpid_str; // scores
            result += "_";
            tmpid_str = std::to_string(outBuff[i][3]);
            result += tmpid_str; // xmin
            result += "_";
            tmpid_str = std::to_string(outBuff[i][4]);
            result += tmpid_str; // ymin
            result += "_";
            tmpid_str = std::to_string(outBuff[i][5]);
            result += tmpid_str; // xmax
            result += "_";
            tmpid_str = std::to_string(outBuff[i][6]);
            result += tmpid_str; // ymax
            result += ";";
        }
        return result;
    }
    ```

## Citation

1. Wei Liu, Dragomir Anguelov, Dumitru Erhan, Christian Szegedy, Scott Reed, Cheng-Yang Fu, Alexander C. Berg.European Conference on Computer Vision (ECCV), 2016 (In press).
